# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Film IMDB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PDjX9sVWbUjU8bq29hsEm2B_V1YTDfCW

# Import Library
"""

import pandas as pd

"""# Data Understanding
Dataset movie_metadata adalah dataset IMDB movie yang berisi 5000 baris dengan 28 kolom, dataset di unduh dari website Kaggle. Kita akan mencoba membuat sistem rekomendasi film kepada Users sesuai genre, jika sebelumya Users menonton film dengan genre Horror maka sistem akan merekomendasikan kepada Users pilihan berbagai film bergenre Horror
"""

movie_data = pd.read_csv('movie_metadata.csv')
movie_data

"""Kita lihat di atas jumlah total data kita adalah 5043 baris dengan 28 kolom, kemudian kita akan mencari tau info lebih detail data dengan fungsi info().

# Univariate Exploratory
"""

movie_data.info()

"""Setelah kita jalankan dengan fungsi info(), kita bisa melihat semua variable pada dataser. Di dalamnya terdiri 13 tipe data **Float**, 3 tipe data **integer**, dan 12 tipe data **Object**."""

movie_data.isnull().sum()

"""Kemudian kita mencari tau apakah seluruh data memiliki Missing Value di dalamnya, setelah di cek dengan fungsi isnull().sum() lumayan banyak variable yang memiliki Missing Value.

"""

movie_data.describe()

"""Kita juga akan melihat lebih detail lagi dataset kita menggunakan fungsi describe(). terlihat bermacam-macam nilai pada variable dataset kita, namun karena kita akan membuat sistem rekomendasi film berdasarkan genre, kita tidak perlu banyak variable. Kita akan mengambil variable yang di butuhkan saja yaitu, genres, movie_title, num_user_for_reviews.

"""

drop = ['color', 'director_name', 'num_critic_for_reviews', 'duration', 'director_facebook_likes',
                  'actor_3_facebook_likes', 'actor_2_name', 'actor_1_facebook_likes', 'gross', 'actor_1_name',
                  'num_voted_users', 'cast_total_facebook_likes', 'actor_3_name', 'facenumber_in_poster', 'plot_keywords',
                  'movie_imdb_link', 'language', 'country', 'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',
                  'imdb_score', 'aspect_ratio', 'movie_facebook_likes']

movie_data.drop(drop, axis=1, inplace=True)

"""Kita membuat variable drop untuk membuang banyak atribut di dalam dataset kita, dengan begitu dataset kita menjadi sangat simple tapi tetap berfungsi dengan baik.

Setelah variable drop dengan isi atribute yang ingin kita buang telah di buat, maka kita juga akan menghapus variable tersebut dari dataset menggunakan fungsi drop().
"""

movie_data

"""Kemudian kita cek dataset kita yang baru, terlihat seperti contoh di atas. Dataset jadi hanya 3 kolom yang tadinya berjumlah 28 kolom.


*   genres : Genre dari masing-masing film.
*   movie_title : Berisi judul-judul film.
*   num_user_for_reviews : Berisi review Users atas film tersebut.





"""

print("Jumlah data rewview users adalah: ", len(movie_data.num_user_for_reviews.unique()))
print("Jumlah data nama movie adalah: ", len(movie_data.movie_title.unique()))
print("Jumlah data nama genre adalah: ", len(movie_data.genres.unique()))

"""Kita juga melihat panjang dari data dengan fungsi unique() agar menghindari data dengan hitungan duplikat.

# Data Preparation

Kita tidak melakukan tahap Data Preprocessing karena kita hanya memiliki satu file utuh, kita tidak melakukan penggabungan data pada kasus ini. Jadi kita langsung mulai ke tahap Data Preparation
"""

movie_data.isnull().sum()

"""Sebelumnya kita melihat pada data utuh banyak sekali kita mendapati Missing Value, namun kita juga akan memeriksanya kembali dengan fungsi yang sama.

Dan setelah data di pisah, kemudian kita melihat Missing Value pada data, terlihat hanya atribut num_user_for_reviews yang memiliki Missing Value dengan total Missing 21 baris.
"""

movie_data = movie_data.dropna()

"""Kita akan menghapus data Missing tersebut dengan fungsi dropna(), dengan fungsi tersebut kita bisa otomatis membuang baris pada kolom yang mengandung Missing Value."""

movie_data.isnull().sum()

"""Setelah kita cek kembali data kita dengan isnull().sum(), data kita telah bersih dari Missing Value atau nilai kosong."""

# Mengurutkan movie_data berdasarkan Review Users
movie_data = movie_data.sort_values('num_user_for_reviews', ascending=True)
movie_data

"""Setelah kita urutkan dengan fungsi sort_values(), bisa dilihat pada kolom num_user_for_reviews bahwa data di urutkan dari yang terkecil hingga yang terbesar. 
Dengan review yang paling sedikit sebanyak 1 sampai yang terbanyak yaitu 5060 review
"""

len(movie_data.num_user_for_reviews.unique())

"""Kita coba cek data kita dengan memfilterya dengan unique(), jumlah nya adalah 954."""

movie_data = movie_data.drop_duplicates('num_user_for_reviews')
movie_data

"""Setelah itu kita akan menghapus juga data agar tidak memiliki duplikat data, kita menghapuskan data berdasarkan review users."""

# konversi data series menjadi list

genres = movie_data['genres'].tolist()

movie = movie_data['movie_title'].tolist()

review_user = movie_data['num_user_for_reviews'].tolist()

"""Selanjutnya kita mengkonversikan data kita menjadi data list, dengan fungsi tolist() data kita akan di jadikan data list."""

print(len(genres))
print(len(movie))
print(len(review_user))

"""Kita juga ingin cek jumlah total data kita dari masing-masing atribut, setiap atribute memiliki jumlah yang sama yaitu 954, Bagus!"""

movie

"""Namun kita memiliki problem pada kasus kita saat membuat sistem rekomendasi, yaitu tiba-tiba data film kita setelah di jadikan list menjadi berubah. Bisa kita lihat di atas nama setiap film menjadi ada tambahan di belakangnya yaitu **\ax0**.

Ini akan akan sangat mengganggu ketika kita ingin mencari rekomendasi film yang serupa berdasarkan genre, karena kita harus memasukan **\ax0** setelah menulis judul film, kita tidak menginginkan itu.

Jadi kita putuhkan untuk menghapus tulisan tersebut dari data film kita.
"""

movie = list(map(lambda st: str.replace(st, "\xa0", ""), movie))
movie

"""Dengan lamda dan melakukan replace pada data film, kita sudah membuang tulisan yang mengganggu tersebut. Sekarang data kita sudah benar-benar bersih dari gangguan."""

movie_new = pd.DataFrame({
    'review_users' : review_user,
    'movie' : movie,
    'genre' : genres
})
movie_new

"""Selanjutnya kita akan membuat Dictionary dari data yang sudah kita perbaiki sebelumnya untuk menentukan key:value pada setiap atribut.

# Model Development with Content Based Filtering

Sampai di mana kita pada tahapan Model Development menggunakan metode Based Filtering.
"""

data = movie_new
data.sample(10)

"""Kita membuat variable baru bernama **data** lalu melihat sample acak sebanyak 10 baris.

Kita akan membangun model sistem rekomendasi sederhana film berdasarkan genrenya, teknik yang kita gunakan adalah dengan TF-IDF Vectorizer.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre
tf.fit(data['genre']) 
 
tf.get_feature_names()

"""Kemudian kita fit_tranform data genre dalam bentuk matrik."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['genre']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Kita bisa melihatnya dengan fungsi todense()"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Selanjutnya, kita akan lihat matriks tf-idf untuk beberapa nama film dan kategori genrenya"""

# Membuat dataframe untuk melihat tf-idf matrix
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.movie
).sample(22, axis=1).sample(10, axis=0)

"""Kita bisa lihat hasil di atas, sebagai contoh pada film Grown Ups memiliki sekitar 1.0 bergenre Comedy.

Dari sini kita sudah berhasil merepresantasikan fitur penting pada kategori genre, dan menunjukan korelasi film terhadap genrenya.

Kemudian kita akan menghitung derajat kesamaan antar film dengan teknik Cosine Similarity, kita akan menggunakan library scikit-learn untuk menggunakan teknik Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
genre_sim = cosine_similarity(tfidf_matrix) 
genre_sim

"""Kemudian kita akan melihat hasil dari kesamaan antar film yang telah kita lakukan pada teknik Cosine Similarity."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
genre_sim_df = pd.DataFrame(genre_sim, index=data['movie'], columns=data['movie'])
print('Shape:', genre_sim_df.shape)
 
# Melihat similarity matrix pada setiap film
genre_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Yang perlu di perhatikan kenapa kesamaan nya tidak mencapai angka 1.0 adalah karena kita memiliki film dengan genre lebih dari satu. Namun kalau kita mencoba mencari secara lengkap ada film dengan kesamaan 1.0. 

Jadi kita coba merekomendasikan sebuah film kepada Users berdasarkan genrenya, dan sebuah genre pun bermacam macam.

## Melihat Hasil Rekomendasi
"""

def film_recommendations(nama_movie, similarity_data=genre_sim_df, items=data[['movie', 'genre']], k=5):
    
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(nama_movie, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Kita akan coba masukan film Avatar, jika kita lihat Avatar memiliki 4 genre yaitu Action, Adventure, Fantasy, dan Sci-Fi. Kita akan mencoba merekomdasikan sebuah film dari genre tersebut."""

data[data.movie.eq('Avatar')]

film_recommendations('Avatar')

"""Menarik! Ternyata ada film dengan 4 genre yang sama, tentu dengan nama film yang berbeda. Jadi kita akan merekomendasikan film tersebut kepada Users, barangkali tertarik."""

